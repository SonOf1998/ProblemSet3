{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Weather forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preparation I extracted the full dataset available on http://idojarasbudapest.hu/archivalt-idojaras into *weather_data.csv* and did a little bit of feature engineering in LibreOffice Calc. I removed the columns related to wind and rain, and merged the t_min and t_max columns into one column by averaging those. Also, I split the date column into a year, month and a day part (so the model may be able to learn the years that was warmer, the cold months, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(123456789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the .csv with pandas and check the column types. For some reason the **YEAR** became float so I converted it back to integer, which was in reality completely redundant, but the preview this way will be a little bit nicer as we will not get any decimal points appearing in the **YEAR** column when calling *tail()* or *head()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weather_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR           float64\n",
       "MONTH            int64\n",
       "DAY              int64\n",
       "TEMPERATURE    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"YEAR\"] = df[\"YEAR\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>TEMPERATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  DAY  TEMPERATURE\n",
       "0  2011      9   29         18.5\n",
       "1  2011      9   30         17.5\n",
       "2  2011     10    1         18.0\n",
       "3  2011     10    2         18.5\n",
       "4  2011     10    3         17.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>TEMPERATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      YEAR  MONTH  DAY  TEMPERATURE\n",
       "3296  2020     10   19         11.1\n",
       "3297  2020     10   20         12.2\n",
       "3298  2020     10   21         12.8\n",
       "3299  2020     10   22         13.0\n",
       "3300  2020     10   23         13.6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the DataFrame returned by read_csv into a feature array **X** and a label array **y**.  \n",
    "\n",
    "**df_X** still contains the headline, so by extracting *values* (which is an nparray type of object) we can easily get rid of it! I did the very same with **df_y**.\n",
    "\n",
    "I reshaped **y** into 2D as I prefer dealing with 2D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[[\"YEAR\", \"MONTH\", \"DAY\"]]\n",
    "df_y = df[\"TEMPERATURE\"]\n",
    "\n",
    "X = df_X.values\n",
    "y = df_y.values\n",
    "y = y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I scaled down the features in the following step. I was experimenting with MinMaxScaler and StandardScaler but I eventually chose StandardScaler even though they both performed identically well. Also, I made a train and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state=123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout creating the model I was using Dense layers with ReLU activations. For the larger hidden layers I enabled dropout regularization.  Also I'm using the ModelCheckpoint callback for saving the best model (the one with the lowest validation loss).\n",
    "\n",
    "I was about to use EarlyStopping here as well, but due to the low number of epochs I felt it sort of unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(units=32, activation=\"relu\", input_shape=(X.shape[1],)),\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        Dropout(0.25),\n",
    "        Dense(units=256, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        Dropout(0.25),\n",
    "        Dense(units=64, activation=\"relu\"),\n",
    "        Dense(units=32, activation=\"relu\"),\n",
    "        Dense(units=y.shape[1], activation=\"relu\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "#es = EarlyStopping(monitor=\"val_loss\", patience=25)\n",
    "mc = ModelCheckpoint(\"best_model\", monitor=\"val_loss\", save_weights_only=True, save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use RMSprop as the optimizer and MSE as the loss function. I train the model with the parameters that can be seen in the fit function. After the training ends I load the best model back to **model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 22.24934, saving model to best_model\n",
      "333/333 - 1s - loss: 91.2583 - mse: 91.2583 - val_loss: 22.2493 - val_mse: 22.2493\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 22.24934 to 18.84693, saving model to best_model\n",
      "333/333 - 0s - loss: 23.3958 - mse: 23.3958 - val_loss: 18.8469 - val_mse: 18.8469\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 18.84693\n",
      "333/333 - 0s - loss: 20.5763 - mse: 20.5763 - val_loss: 27.0613 - val_mse: 27.0613\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 18.84693 to 14.73520, saving model to best_model\n",
      "333/333 - 0s - loss: 19.5095 - mse: 19.5095 - val_loss: 14.7352 - val_mse: 14.7352\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 14.73520\n",
      "333/333 - 0s - loss: 19.5253 - mse: 19.5253 - val_loss: 16.1400 - val_mse: 16.1400\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 14.73520\n",
      "333/333 - 0s - loss: 18.6319 - mse: 18.6319 - val_loss: 15.4813 - val_mse: 15.4813\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 14.73520\n",
      "333/333 - 0s - loss: 18.4594 - mse: 18.4594 - val_loss: 16.1270 - val_mse: 16.1270\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 14.73520\n",
      "333/333 - 0s - loss: 17.9346 - mse: 17.9346 - val_loss: 15.0312 - val_mse: 15.0312\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 14.73520\n",
      "333/333 - 0s - loss: 17.3389 - mse: 17.3389 - val_loss: 15.4138 - val_mse: 15.4138\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 14.73520\n",
      "333/333 - 0s - loss: 17.3535 - mse: 17.3535 - val_loss: 16.3622 - val_mse: 16.3622\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 14.73520\n",
      "333/333 - 0s - loss: 17.2233 - mse: 17.2233 - val_loss: 18.2659 - val_mse: 18.2659\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 14.73520 to 14.72253, saving model to best_model\n",
      "333/333 - 0s - loss: 16.5743 - mse: 16.5743 - val_loss: 14.7225 - val_mse: 14.7225\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 14.72253\n",
      "333/333 - 0s - loss: 16.7209 - mse: 16.7209 - val_loss: 14.9267 - val_mse: 14.9267\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 14.72253\n",
      "333/333 - 0s - loss: 17.0838 - mse: 17.0838 - val_loss: 15.3924 - val_mse: 15.3924\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 14.72253\n",
      "333/333 - 0s - loss: 16.2042 - mse: 16.2042 - val_loss: 15.5427 - val_mse: 15.5427\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 14.72253\n",
      "333/333 - 0s - loss: 16.5503 - mse: 16.5503 - val_loss: 15.1274 - val_mse: 15.1274\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 14.72253\n",
      "333/333 - 0s - loss: 16.6974 - mse: 16.6974 - val_loss: 14.8947 - val_mse: 14.8947\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 14.72253 to 14.33287, saving model to best_model\n",
      "333/333 - 0s - loss: 16.6691 - mse: 16.6691 - val_loss: 14.3329 - val_mse: 14.3329\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 14.33287\n",
      "333/333 - 1s - loss: 15.9347 - mse: 15.9347 - val_loss: 19.2414 - val_mse: 19.2414\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 14.33287\n",
      "333/333 - 0s - loss: 15.9086 - mse: 15.9086 - val_loss: 15.8860 - val_mse: 15.8860\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 14.33287\n",
      "333/333 - 1s - loss: 15.3633 - mse: 15.3633 - val_loss: 18.3202 - val_mse: 18.3202\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 14.33287\n",
      "333/333 - 1s - loss: 15.8609 - mse: 15.8609 - val_loss: 15.4202 - val_mse: 15.4202\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 14.33287\n",
      "333/333 - 1s - loss: 15.8274 - mse: 15.8274 - val_loss: 14.9332 - val_mse: 14.9332\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 14.33287\n",
      "333/333 - 1s - loss: 16.3192 - mse: 16.3192 - val_loss: 16.3385 - val_mse: 16.3385\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 14.33287\n",
      "333/333 - 0s - loss: 15.7959 - mse: 15.7959 - val_loss: 14.7835 - val_mse: 14.7835\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 14.33287\n",
      "333/333 - 0s - loss: 15.7603 - mse: 15.7603 - val_loss: 15.3704 - val_mse: 15.3704\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 14.33287\n",
      "333/333 - 0s - loss: 15.4221 - mse: 15.4221 - val_loss: 17.1339 - val_mse: 17.1339\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 14.33287\n",
      "333/333 - 0s - loss: 15.4623 - mse: 15.4623 - val_loss: 14.6531 - val_mse: 14.6531\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss improved from 14.33287 to 13.87673, saving model to best_model\n",
      "333/333 - 0s - loss: 15.3910 - mse: 15.3910 - val_loss: 13.8767 - val_mse: 13.8767\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 15.4671 - mse: 15.4671 - val_loss: 15.9934 - val_mse: 15.9934\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 15.7681 - mse: 15.7681 - val_loss: 14.1332 - val_mse: 14.1332\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 15.1330 - mse: 15.1330 - val_loss: 14.1829 - val_mse: 14.1829\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 15.2336 - mse: 15.2336 - val_loss: 14.6881 - val_mse: 14.6881\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 14.9985 - mse: 14.9985 - val_loss: 16.2744 - val_mse: 16.2744\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 15.2074 - mse: 15.2074 - val_loss: 14.6363 - val_mse: 14.6363\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 15.2881 - mse: 15.2881 - val_loss: 14.5289 - val_mse: 14.5289\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 15.0836 - mse: 15.0836 - val_loss: 13.9478 - val_mse: 13.9478\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 15.2195 - mse: 15.2195 - val_loss: 15.2130 - val_mse: 15.2130\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 15.1414 - mse: 15.1414 - val_loss: 17.1784 - val_mse: 17.1784\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 14.6824 - mse: 14.6824 - val_loss: 15.4412 - val_mse: 15.4412\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 15.0131 - mse: 15.0131 - val_loss: 14.8581 - val_mse: 14.8581\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 14.7808 - mse: 14.7808 - val_loss: 14.5169 - val_mse: 14.5169\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 14.7228 - mse: 14.7228 - val_loss: 16.6335 - val_mse: 16.6335\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 14.3283 - mse: 14.3283 - val_loss: 14.2947 - val_mse: 14.2947\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 14.7416 - mse: 14.7416 - val_loss: 14.1052 - val_mse: 14.1052\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 14.4662 - mse: 14.4662 - val_loss: 14.6080 - val_mse: 14.6080\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 14.2384 - mse: 14.2384 - val_loss: 14.7603 - val_mse: 14.7603\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 13.87673\n",
      "333/333 - 1s - loss: 14.6333 - mse: 14.6333 - val_loss: 14.2323 - val_mse: 14.2323\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 13.87673\n",
      "333/333 - 0s - loss: 14.6816 - mse: 14.6816 - val_loss: 13.8905 - val_mse: 13.8905\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss improved from 13.87673 to 13.72227, saving model to best_model\n",
      "333/333 - 1s - loss: 14.5580 - mse: 14.5580 - val_loss: 13.7223 - val_mse: 13.7223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe1d06efc40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=RMSprop(), loss=\"mse\", metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=2, validation_split=0.15, shuffle=True, callbacks=[mc])\n",
    "model.load_weights(\"best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for measuring how good or bad the model performs on the training set I calculate the absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 166 days, the summed absolute error is 477.7634516477585\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "print(\"For\", len(X_test), \"days, the summed absolute error is\", np.sum(np.abs(y_preds - y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**October 28.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.433494 °C\n"
     ]
    }
   ],
   "source": [
    "y_oct28 = model.predict(scaler.transform([[2020, 10, 28]]))\n",
    "print(*y_oct28[0], \"°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**November 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.182936 °C\n"
     ]
    }
   ],
   "source": [
    "y_nov3 = model.predict(scaler.transform([[2020, 11, 3]]))\n",
    "print(*y_nov3[0], \"°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**November 24.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1978006 °C\n"
     ]
    }
   ],
   "source": [
    "y_nov24 = model.predict(scaler.transform([[2020, 11, 24]]))\n",
    "print(*y_nov24[0], \"°C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
